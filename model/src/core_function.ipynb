{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ff9476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import json\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d9980c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_from_directory(TRAIN_DIR):\n",
    "    j = 0\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    for i in os.listdir(TRAIN_DIR):\n",
    "        print(\"class\", i, \":\", os.listdir(TRAIN_DIR + \"/\" + i)[0])\n",
    "        img = mpimg.imread(TRAIN_DIR+\"/\"+i+\"/\"+os.listdir(TRAIN_DIR+\"/\"+i)[0])\n",
    "        fig.add_subplot(2, 3, j+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(img, cmap=plt.cm.binary)\n",
    "        plt.xlabel(i)\n",
    "        j += 1\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c771910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_directory_info(DIR):\n",
    "    for i in os.listdir(DIR):\n",
    "        files = os.listdir(os.path.join(DIR, i))\n",
    "        print(f'{i} : {len(files)} files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fa022fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_early_stopping_settings_string(EARLY_STOPPING):\n",
    "    if str(EARLY_STOPPING.monitor_op) == \"<ufunc 'less'>\":\n",
    "        mode_value = \"min\"\n",
    "    elif str(EARLY_STOPPING.monitor_op) == \"<ufunc 'greater'>\":\n",
    "        mode_value = \"max\"\n",
    "    else:\n",
    "        mode_value = str(EARLY_STOPPING.monitor_op)\n",
    "\n",
    "    early_stopping_settings = {\n",
    "        'monitor': EARLY_STOPPING.monitor,\n",
    "        'min_delta': EARLY_STOPPING.min_delta,\n",
    "        'patience': EARLY_STOPPING.patience,\n",
    "        'mode': mode_value,\n",
    "        'baseline': EARLY_STOPPING.baseline,\n",
    "        'restore_best_weights': EARLY_STOPPING.restore_best_weights,\n",
    "    }\n",
    "    early_stopping_settings = json.dumps(early_stopping_settings)\n",
    "    \n",
    "    return early_stopping_settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a561e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reduce_lr_settings_string(REDUCE_LR):\n",
    "    reduce_lr_settings = {\n",
    "        'monitor': REDUCE_LR.monitor,\n",
    "        'factor': REDUCE_LR.factor,\n",
    "        'patience': REDUCE_LR.patience,\n",
    "        'mode': REDUCE_LR.mode,\n",
    "        'min_delta': REDUCE_LR.min_delta,\n",
    "        'cooldown': REDUCE_LR.cooldown,\n",
    "        'min_lr': REDUCE_LR.min_lr\n",
    "    }\n",
    "    reduce_lr_settings = json.dumps(reduce_lr_settings)\n",
    "\n",
    "    \n",
    "    return reduce_lr_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7996cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_checkpoint_settings_string(MODEL_CHECKPOINT):\n",
    "    if str(MODEL_CHECKPOINT.monitor_op) == \"<ufunc 'less'>\":\n",
    "        mode_value = \"min\"\n",
    "    elif str(MODEL_CHECKPOINT.monitor_op) == \"<ufunc 'greater'>\":\n",
    "        mode_value = \"max\"\n",
    "    else:\n",
    "        mode_value = str(MODEL_CHECKPOINT.monitor_op)\n",
    "\n",
    "    checkpoint_settings = {\n",
    "        'monitor': MODEL_CHECKPOINT.monitor,\n",
    "        'save_best_only': MODEL_CHECKPOINT.save_best_only,\n",
    "        'save_weights_only': MODEL_CHECKPOINT.save_weights_only,\n",
    "        'mode': mode_value,\n",
    "        'save_freq': MODEL_CHECKPOINT.save_freq\n",
    "    }\n",
    "    checkpoint_settings = json.dumps(checkpoint_settings)\n",
    "\n",
    "    return checkpoint_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecb32a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_time():\n",
    "    return datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f8e3205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_saving_path(SAVED_MODEL_DIR, MODEL_BASE_NAME):\n",
    "    current_time = get_current_time()\n",
    "    try:\n",
    "        os.mkdir(SAVED_MODEL_DIR)\n",
    "    except OSError as error:\n",
    "        next\n",
    "    SavingModelPath = SAVED_MODEL_DIR+\"/\"+MODEL_BASE_NAME+\"_\"+current_time\n",
    "    try:\n",
    "        os.mkdir(SavingModelPath)\n",
    "    except OSError as error:\n",
    "        next\n",
    "        \n",
    "    return SavingModelPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dee439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_base_model(MODEL_BASE_NAME):\n",
    "    # Get the model class from the global namespace\n",
    "    try:\n",
    "        model_class = globals()[MODEL_BASE_NAME]\n",
    "        conv_base = model_class(\n",
    "            weights='imagenet',\n",
    "            include_top=False,\n",
    "            input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "        )\n",
    "        print(\"Using \"+MODEL_BASE_NAME+\" as base conv\")\n",
    "        return MODEL_BASE_NAME\n",
    "    except Exception as error:\n",
    "        print(\"error: \"+str(error))\n",
    "        print(\"\")\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "\n",
    "def check_optimizer(OPTIMIZER):\n",
    "    # Get the model class from the global namespace\n",
    "    try:\n",
    "        optimizer=getattr(optimizers, OPTIMIZER)\n",
    "        print(\"Using \"+OPTIMIZER+\" as base optimizers\")\n",
    "        return OPTIMIZER\n",
    "    except Exception as error:\n",
    "        print(\"error: \"+str(error))\n",
    "        print(\"No \"+OPTIMIZER+\" optimizers\")\n",
    "        print(\"\")\n",
    "        return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12fbdd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUTOTUNE(train_ds, val_ds, test_ds):\n",
    "    train_ds = train_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    val_ds = val_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    test_ds = test_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83773cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_loss(history):\n",
    "\n",
    "    train_acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(train_acc)+1)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_acc, label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, label='Validation accuracy', color='red')\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(SavingModelPath+\"/\"+ \"IMG_\" +MODEL_BASE_NAME+\"_AccPlot.png\", dpi=300)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_loss, label='Training loss')\n",
    "    plt.plot(epochs, val_loss, label='Validation loss', color='red')\n",
    "    plt.title(\"Training and Validation loss\")\n",
    "    plt.legend()\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(SavingModelPath+\"/\" + \"IMG_\" + MODEL_BASE_NAME+\"_LossPlot.png\", dpi=300)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Average Validation loss: \", np.mean(val_loss))\n",
    "    print(f\"Average Validation accuracy: {np.mean(val_acc)*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "219ce13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test_ds, SavingModelPath, model, MODEL_BASE_NAME):\n",
    "    # Evaluate the model on the test dataset\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "    for images, labels in test_ds:\n",
    "        predictions = model.predict(images, verbose=0)\n",
    "        predicted_labels = np.argmax(predictions, axis=1)\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted_labels)\n",
    "        \n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "    # Calculate the elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    \n",
    "    report_model = classification_report(y_true, y_pred, digits=5)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(6, 4))  # Adjust the figure size as needed\n",
    "    plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues, vmin=0, vmax=1.0)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "\n",
    "    # Add labels to the confusion matrix plot\n",
    "    thresh = cm_normalized.max() / 2.0\n",
    "    for i, j in np.ndindex(cm_normalized.shape):\n",
    "        plt.text(j, i, format(cm_normalized[i, j], '.2f'), ha='center', va='center', color='white' if cm_normalized[i, j] > thresh else 'black',fontsize=15)\n",
    "\n",
    "    # Save the confusion matrix plot\n",
    "    fig = plt.gcf()\n",
    "    fig.savefig(SavingModelPath + \"/\" + \"IMG_\" + MODEL_BASE_NAME + \"_Acc_\" + str(round(accuracy * 100, 3) ) + \".png\", dpi=300)\n",
    "\n",
    "    plt.show()\n",
    "    return accuracy, elapsed_time, report_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4158f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_to_list(rep, class_names):\n",
    "    if type(rep) == str:\n",
    "        lines = rep.split('\\n')\n",
    "        values = [line.split()[0:] for line in lines[0:]]\n",
    "        values = [item for item in values if item]\n",
    "        values = [item for item in values if item]\n",
    "\n",
    "        for i in range(0,len(values)):\n",
    "            if(i==0):\n",
    "                values[i].insert(0, '')\n",
    "            elif(i>len(values)-2-1):\n",
    "                values[i][0] = ' '.join(values[i][0:2])\n",
    "                del values[i][1]\n",
    "            elif(i>len(values)-3-1):\n",
    "                values[i].insert(1, '')\n",
    "                values[i].insert(1, '')\n",
    "\n",
    "            else:\n",
    "                values[i][0] = class_names[int(values[i][0])]\n",
    "\n",
    "        return values\n",
    "    else:\n",
    "        print(\"report must be str\")\n",
    "        return rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b8c5b",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d33ec6",
   "metadata": {},
   "source": [
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f665679",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a982c3fc",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a08a73b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS IS OLD SETTING\n",
    "\n",
    "# EARLY_STOPPING = callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=8, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True,)\n",
    "# REDUCE_LR = callbacks.ReduceLROnPlateau(monitor=\"val_acc\", factor=0.6, patience=8, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=0, min_lr=1e-6,)\n",
    "# MODEL_CHECKPOINT = callbacks.ModelCheckpoint(\n",
    "#     os.path.join(SavingModelPath, MODEL_BASE_NAME+\"_ModelH5_\"+f\"{current_time}\"+\".h5\"),\n",
    "#     monitor = \"val_loss\", verbose = 1, save_best_only = True, save_weights_only = False, mode = \"max\", save_freq=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a36b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS NEW SETTING\n",
    "\n",
    "# ### Check default setting at core_function.ipynb\n",
    "# EARLY_STOPPING = callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=5, verbose=1, mode=\"auto\", baseline=0.4, restore_best_weights=True,)\n",
    "# #https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
    "# #https://pub.towardsai.net/keras-earlystopping-callback-to-train-the-neural-networks-perfectly-2a3f865148f7\n",
    "\n",
    "# REDUCE_LR = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3, patience=3, verbose=1, mode=\"auto\", min_delta=0.0001, cooldown=0, min_lr=1e-6,)\n",
    "# MODEL_CHECKPOINT = callbacks.ModelCheckpoint(\n",
    "#     os.path.join(SavingModelPath, \"H5Model_\"+MODEL_BASE_NAME+\"_BestEpoch.h5\"),\n",
    "#     monitor = \"val_acc\", verbose = 1, save_best_only = True, save_weights_only = False, mode = \"auto\", save_freq=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf4a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
